{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK15L761L747",
        "outputId": "33812a62-c11e-459c-bbeb-0c382fde3159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GV_DeepLearning'...\n",
            "remote: Enumerating objects: 1607, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 1607 (delta 4), reused 15 (delta 2), pack-reused 1589\u001b[K\n",
            "Receiving objects: 100% (1607/1607), 29.99 MiB | 37.32 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/vadivukar/GV_DeepLearning.git/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "SwT_-h-RMgXR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rmiKFedkMNmM",
        "outputId": "e7d31a8f-1b6a-4002-b996-6bdff5fad69c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/dataset /dataset cnn dog cat/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqkSzNwlNnGY",
        "outputId": "0fb158b1-54f4-4ab9-8080-9445f28b413c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/dataset /dataset cnn dog cat/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WpyotUpN8EK",
        "outputId": "51b48c1d-fcf8-4f86-b8d2-ce7bde9ee7ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**first initialize the CNN**"
      ],
      "metadata": {
        "id": "8G-RCCg-luOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "2lpkDn8WODHg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**stp 1 - convolution**"
      ],
      "metadata": {
        "id": "kg5AESnsmH8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "id": "N86reAImOKim"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "7ixYgaUhOOg3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step2-maxpooling**"
      ],
      "metadata": {
        "id": "N7u0Ht3tmNQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "ZCpogzsIOScD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#step3-flattening**"
      ],
      "metadata": {
        "id": "tz-YzkZfmRQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "LpQb1GkhOwdV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#step4-fullconnection**"
      ],
      "metadata": {
        "id": "VunFXbKZmW5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "0xWxPD1DOzno"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "t0gFJcqKO3ad"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "QYoOGouCO7JF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**fitting our model to the training set"
      ],
      "metadata": {
        "id": "GrbRAF-ElWI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tziUbNpbO9y-",
        "outputId": "04a159c7-e5f7-4fc1-aad7-3f5a2fdbcbff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 19s 4s/step - loss: 0.8252 - accuracy: 0.5200 - val_loss: 0.8212 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 1s 334ms/step - loss: 0.7250 - accuracy: 0.5000 - val_loss: 0.6966 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 1s 343ms/step - loss: 0.6916 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.6909 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 1s 237ms/step - loss: 0.6908 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 1s 341ms/step - loss: 0.6826 - accuracy: 0.5100 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.6734 - accuracy: 0.5500 - val_loss: 0.7050 - val_accuracy: 0.4500\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.6673 - accuracy: 0.5900 - val_loss: 0.7388 - val_accuracy: 0.4500\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 0.6345 - accuracy: 0.5900 - val_loss: 0.7248 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 1s 243ms/step - loss: 0.6338 - accuracy: 0.6900 - val_loss: 0.7082 - val_accuracy: 0.5500\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 1s 260ms/step - loss: 0.6088 - accuracy: 0.6500 - val_loss: 0.7205 - val_accuracy: 0.4500\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 1s 258ms/step - loss: 0.6364 - accuracy: 0.6800 - val_loss: 0.8175 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.6215 - accuracy: 0.6600 - val_loss: 0.8544 - val_accuracy: 0.4500\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 1s 344ms/step - loss: 0.5704 - accuracy: 0.7300 - val_loss: 0.7672 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 1s 351ms/step - loss: 0.5854 - accuracy: 0.7400 - val_loss: 0.7983 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 1s 251ms/step - loss: 0.5528 - accuracy: 0.7000 - val_loss: 0.7616 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 1s 352ms/step - loss: 0.5155 - accuracy: 0.7600 - val_loss: 0.8297 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 1s 368ms/step - loss: 0.5350 - accuracy: 0.7500 - val_loss: 0.8532 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 1s 345ms/step - loss: 0.5602 - accuracy: 0.6900 - val_loss: 0.8868 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 1s 242ms/step - loss: 0.4628 - accuracy: 0.7900 - val_loss: 0.9814 - val_accuracy: 0.4500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f10a6377490>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**"
      ],
      "metadata": {
        "id": "wr3f7xgplem9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/drive/MyDrive/dataset /dataset cnn dog cat/single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "metadata": {
        "id": "1tLwUrY1PAQ0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2NoBzTUP35U",
        "outputId": "efed0d87-71ff-42d9-c7ad-33f9693dd350"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4FXY0diaP6hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t4wdYjHqknW3"
      }
    }
  ]
}